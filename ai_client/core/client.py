"""
–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å AIClient - –£–ü–†–û–©–ï–ù–ù–ê–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–ê
"""

import os
import time
import logging
import re
from typing import Optional, Dict, Any, AsyncGenerator, List
from datetime import datetime
import json
from dotenv import load_dotenv
import base64

# –ò–º–ø–æ—Ä—Ç—ã –∏–∑ –º–æ–¥—É–ª–µ–π
from ..models.gemini_client import GeminiClient
from ..tools.file_tools import FileTools
from ..tools.memory_tools import MemoryTools
from ..tools.system_tools import SystemTools
from ..tools.vision_tools import VisionTools
from ..utils.config import Config
from ..utils.logger import Logger
from ..utils.error_handler import ErrorHandler

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

class AIClient:
    """
    –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π AI –∫–ª–∏–µ–Ω—Ç - –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ –º–æ–¥—É–ª–∏
    """
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è AI –∫–ª–∏–µ–Ω—Ç–∞"""
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —É—Ç–∏–ª–∏—Ç—ã
        self.config = Config()
        self.logger = Logger()
        self.error_handler = ErrorHandler()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥—É–ª–∏
        self.gemini_client = GeminiClient()
        self.file_tools = FileTools()
        self.memory_tools = MemoryTools()
        self.system_tools = SystemTools()
        self.vision_tools = VisionTools()
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ–º–ø—Ç
        # Load the system prompt directly from file
        with open("prompts/guardian_prompt.py", "r", encoding="utf-8") as f:
            self.base_prompt = f.read()
        
        self.logger.info("üöÄ AIClient initialized with simplified architecture")
    
    # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã - –¥–µ–ª–µ–≥–∏—Ä—É–µ–º –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –º–æ–¥—É–ª–∏
    
    def get_current_model(self) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å –∏–º—è —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–∏"""
        return self.gemini_client.get_current_model()
    
    def switch_to_model(self, model_name: str) -> bool:
        """–ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å—Å—è –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –º–æ–¥–µ–ª—å"""
        return self.gemini_client.switch_to_model(model_name)
    
    def get_model_status(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–µ–π"""
        return self.gemini_client.get_model_status()
    
    # –ú–µ—Ç–æ–¥—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤
    async def generate_streaming_response(
        self, 
        user_message: str, 
        context: Optional[str] = None,
        user_profile: Optional[Dict[str, Any]] = None,
        additional_prompt: Optional[str] = None,
        image_path: Optional[str] = None
    ) -> AsyncGenerator[str, None]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è streaming –æ—Ç–≤–µ—Ç–∞ —Å –µ–¥–∏–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º –∏ –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
        # –°–æ–±–∏—Ä–∞–µ–º –ø–æ–ª–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        full_prompt = self.base_prompt
        if additional_prompt:
            full_prompt += f"\n\n{additional_prompt}"
        
        async for chunk in self.gemini_client.generate_streaming_response(
            full_prompt, user_message, context, user_profile, image_path
        ):
            yield chunk
    
    def chat(
        self, 
        message: str, 
        user_profile: Optional[Dict[str, Any]] = None,
        conversation_context: Optional[str] = None,
        additional_prompt: Optional[str] = None,
        image_path: Optional[str] = None
    ) -> str:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ —á–∞—Ç–∞ —Å –µ–¥–∏–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º –∏ –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
        # –°–æ–±–∏—Ä–∞–µ–º –ø–æ–ª–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        full_prompt = self.base_prompt
        if additional_prompt:
            full_prompt += f"\n\n{additional_prompt}"
        
        return self.gemini_client.chat(message, user_profile, conversation_context, full_prompt, image_path)
    
    # –ü—Ä—è–º–æ–π –¥–æ—Å—Ç—É–ø –∫ –º–æ–¥—É–ª—è–º –¥–ª—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
    @property
    def files(self):
        """–î–æ—Å—Ç—É–ø –∫ —Ñ–∞–π–ª–æ–≤—ã–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º"""
        return self.file_tools
    
    @property
    def memory(self):
        """–î–æ—Å—Ç—É–ø –∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º –ø–∞–º—è—Ç–∏"""
        return self.memory_tools
    
    @property
    def system(self):
        """–î–æ—Å—Ç—É–ø –∫ —Å–∏—Å—Ç–µ–º–Ω—ã–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º"""
        return self.system_tools
    
    @property
    def vision(self):
        """–î–æ—Å—Ç—É–ø –∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º –∑—Ä–µ–Ω–∏—è"""
        return self.vision_tools
    
    # –£—Ç–∏–ª–∏—Ç–∞—Ä–Ω—ã–µ –º–µ—Ç–æ–¥—ã
    def _extract_tool_calls(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—ã–∑–æ–≤–æ–≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        return self.system_tools._extract_tool_calls(text)
    
    def _extract_nested_calls(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö –≤—ã–∑–æ–≤–æ–≤"""
        return self.system_tools._extract_nested_calls(text)
    
    def _parse_arguments(self, args_str: str, expected_params: List[str]) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤"""
        return self.system_tools._parse_arguments(args_str, expected_params)
    
    def _execute_tool_call(self, tool_call: str) -> str:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –≤—ã–∑–æ–≤–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞"""
        return self.system_tools._execute_tool_call(tool_call)
    
    def _get_multi_user_context(self) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"""
        return self.memory_tools._get_multi_user_context() 