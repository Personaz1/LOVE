"""
ŒîŒ£ Guardian Reinforcement Tagger v4.0
–°–∏—Å—Ç–µ–º–∞ –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –æ—Ç –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π
"""

import json
import logging
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import re

from ai_client.core.client import AIClient
from ai_client.utils.logger import Logger
from core.scheduler import scheduler, TaskPriority

logger = Logger()

class FeedbackType(Enum):
    POSITIVE = "positive"
    NEGATIVE = "negative"
    NEUTRAL = "neutral"
    MIXED = "mixed"

class LearningCategory(Enum):
    STYLE_PREFERENCE = "style_preference"
    COMMUNICATION_LEVEL = "communication_level"
    RESPONSE_SPEED = "response_speed"
    TECHNICAL_DEPTH = "technical_depth"
    INTERACTION_PATTERN = "interaction_pattern"
    EMOTIONAL_RESPONSE = "emotional_response"

@dataclass
class InteractionRecord:
    timestamp: datetime
    user: str
    action: str
    context: Dict[str, Any]
    response: Dict[str, Any]
    feedback: Dict[str, Any]
    learning_insights: Dict[str, Any]

class ReinforcementTagger:
    """–°–∏—Å—Ç–µ–º–∞ –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –æ—Ç –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π"""
    
    def __init__(self):
        self.ai_client = AIClient()
        self.interaction_log_file = "memory/interaction_log.jsonl"
        self.learning_patterns: Dict[str, Any] = {}
        self.feedback_weights: Dict[str, float] = {
            "explicit_positive": 1.0,
            "explicit_negative": -1.0,
            "implicit_positive": 0.5,
            "implicit_negative": -0.5,
            "neutral": 0.0
        }
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        self._load_learning_patterns()
        
        logger.info("üéØ ŒîŒ£ Reinforcement Tagger initialized")
    
    def _load_learning_patterns(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –æ–±—É—á–µ–Ω–∏—è"""
        try:
            with open("memory/learning_patterns.json", 'r', encoding='utf-8') as f:
                self.learning_patterns = json.load(f)
        except FileNotFoundError:
            self.learning_patterns = {
                "user_preferences": {},
                "style_adaptations": {},
                "communication_patterns": {},
                "feedback_analysis": {}
            }
    
    def _save_learning_patterns(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –æ–±—É—á–µ–Ω–∏—è"""
        try:
            with open("memory/learning_patterns.json", 'w', encoding='utf-8') as f:
                json.dump(self.learning_patterns, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.error(f"‚ùå Failed to save learning patterns: {e}")
    
    def log_interaction(self, user: str, action: str, context: Dict[str, Any],
                       response: Dict[str, Any], feedback: Dict[str, Any]) -> str:
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è"""
        record = InteractionRecord(
            timestamp=datetime.now(),
            user=user,
            action=action,
            context=context,
            response=response,
            feedback=feedback,
            learning_insights={}
        )
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–Ω—Å–∞–π—Ç–æ–≤
        insights = self._analyze_interaction(record)
        record.learning_insights = insights
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ JSONL —Ñ–∞–π–ª
        self._save_interaction_record(record)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –æ–±—É—á–µ–Ω–∏—è
        self._update_learning_patterns(record)
        
        logger.info(f"üìù Interaction logged: {action} by {user}")
        return record.timestamp.isoformat()
    
    def _analyze_interaction(self, record: InteractionRecord) -> Dict[str, Any]:
        """AI-–∞–Ω–∞–ª–∏–∑ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–Ω—Å–∞–π—Ç–æ–≤"""
        analysis_prompt = f"""
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ –∏ –∏–∑–≤–ª–µ–∫–∏ –∫–ª—é—á–µ–≤—ã–µ –∏–Ω—Å–∞–π—Ç—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è:
        
        –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {record.user}
        –î–µ–π—Å—Ç–≤–∏–µ: {record.action}
        –ö–æ–Ω—Ç–µ–∫—Å—Ç: {json.dumps(record.context, ensure_ascii=False)}
        –û—Ç–≤–µ—Ç: {json.dumps(record.response, ensure_ascii=False)}
        –û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å: {json.dumps(record.feedback, ensure_ascii=False)}
        
        –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π:
        1. –ü—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ —Å—Ç–∏–ª–µ –æ–±—â–µ–Ω–∏—è
        2. –£—Ä–æ–≤–µ–Ω—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –≥–ª—É–±–∏–Ω—ã
        3. –°–∫–æ—Ä–æ—Å—Ç—å –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è
        4. –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        5. –ü—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –æ—Ç–≤–µ—Ç–æ–≤
        
        –í–µ—Ä–Ω–∏ –∞–Ω–∞–ª–∏–∑ –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ.
        """
        
        try:
            response = self.ai_client.chat(analysis_prompt)
            return self._extract_json_from_response(response)
        except Exception as e:
            logger.error(f"‚ùå Interaction analysis failed: {e}")
            return {"error": str(e)}
    
    def _extract_json_from_response(self, response: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ JSON –∏–∑ AI-–æ—Ç–≤–µ—Ç–∞"""
        try:
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
            else:
                return {"raw_response": response}
        except:
            return {"raw_response": response}
    
    def _save_interaction_record(self, record: InteractionRecord):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –≤ JSONL"""
        try:
            with open(self.interaction_log_file, 'a', encoding='utf-8') as f:
                json.dump({
                    "timestamp": record.timestamp.isoformat(),
                    "type": "interaction",
                    "user": record.user,
                    "action": record.action,
                    "context": record.context,
                    "response": record.response,
                    "feedback": record.feedback,
                    "learning_insights": record.learning_insights
                }, f, ensure_ascii=False)
                f.write('\n')
        except Exception as e:
            logger.error(f"‚ùå Failed to save interaction record: {e}")
    
    def _update_learning_patterns(self, record: InteractionRecord):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è"""
        user = record.user
        insights = record.learning_insights
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        if user not in self.learning_patterns["user_preferences"]:
            self.learning_patterns["user_preferences"][user] = {}
        
        user_prefs = self.learning_patterns["user_preferences"][user]
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å
        feedback_score = self._calculate_feedback_score(record.feedback)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∏–ª–µ–≤—ã–µ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏
        if "style_preference" in insights:
            self._update_style_adaptation(user, insights["style_preference"], feedback_score)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        if "communication_level" in insights:
            self._update_communication_pattern(user, insights["communication_level"], feedback_score)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é –≥–ª—É–±–∏–Ω—É
        if "technical_depth" in insights:
            self._update_technical_depth(user, insights["technical_depth"], feedback_score)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        self._save_learning_patterns()
    
    def _calculate_feedback_score(self, feedback: Dict[str, Any]) -> float:
        """–†–∞—Å—á–µ—Ç –æ—Ü–µ–Ω–∫–∏ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏"""
        score = 0.0
        
        # –Ø–≤–Ω–∞—è –æ–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å
        if feedback.get("explicit") == "positive":
            score += self.feedback_weights["explicit_positive"]
        elif feedback.get("explicit") == "negative":
            score += self.feedback_weights["explicit_negative"]
        
        # –ù–µ—è–≤–Ω–∞—è –æ–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å
        if feedback.get("implicit") == "positive":
            score += self.feedback_weights["implicit_positive"]
        elif feedback.get("implicit") == "negative":
            score += self.feedback_weights["implicit_negative"]
        
        return score
    
    def _update_style_adaptation(self, user: str, style: str, feedback_score: float):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∏–ª–µ–≤–æ–π –∞–¥–∞–ø—Ç–∞—Ü–∏–∏"""
        if "style_adaptations" not in self.learning_patterns:
            self.learning_patterns["style_adaptations"] = {}
        
        if user not in self.learning_patterns["style_adaptations"]:
            self.learning_patterns["style_adaptations"][user] = {}
        
        user_styles = self.learning_patterns["style_adaptations"][user]
        
        if style not in user_styles:
            user_styles[style] = {"weight": 0.5, "confidence": 0.0, "usage_count": 0}
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –≤–µ—Å —Å—Ç–∏–ª—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏
        current_weight = user_styles[style]["weight"]
        learning_rate = 0.1
        new_weight = current_weight + (feedback_score * learning_rate)
        user_styles[style]["weight"] = max(0.0, min(1.0, new_weight))
        user_styles[style]["usage_count"] += 1
        user_styles[style]["confidence"] = min(1.0, user_styles[style]["usage_count"] / 10.0)
    
    def _update_communication_pattern(self, user: str, level: str, feedback_score: float):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞"""
        if "communication_patterns" not in self.learning_patterns:
            self.learning_patterns["communication_patterns"] = {}
        
        if user not in self.learning_patterns["communication_patterns"]:
            self.learning_patterns["communication_patterns"][user] = {}
        
        user_patterns = self.learning_patterns["communication_patterns"][user]
        
        if level not in user_patterns:
            user_patterns[level] = {"weight": 0.5, "confidence": 0.0, "usage_count": 0}
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –≤–µ—Å —É—Ä–æ–≤–Ω—è –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏
        current_weight = user_patterns[level]["weight"]
        learning_rate = 0.1
        new_weight = current_weight + (feedback_score * learning_rate)
        user_patterns[level]["weight"] = max(0.0, min(1.0, new_weight))
        user_patterns[level]["usage_count"] += 1
        user_patterns[level]["confidence"] = min(1.0, user_patterns[level]["usage_count"] / 10.0)
    
    def _update_technical_depth(self, user: str, depth: str, feedback_score: float):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –≥–ª—É–±–∏–Ω—ã"""
        if "technical_depth" not in self.learning_patterns:
            self.learning_patterns["technical_depth"] = {}
        
        if user not in self.learning_patterns["technical_depth"]:
            self.learning_patterns["technical_depth"][user] = {}
        
        user_depth = self.learning_patterns["technical_depth"][user]
        
        if depth not in user_depth:
            user_depth[depth] = {"weight": 0.5, "confidence": 0.0, "usage_count": 0}
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –≤–µ—Å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –≥–ª—É–±–∏–Ω—ã
        current_weight = user_depth[depth]["weight"]
        learning_rate = 0.1
        new_weight = current_weight + (feedback_score * learning_rate)
        user_depth[depth]["weight"] = max(0.0, min(1.0, new_weight))
        user_depth[depth]["usage_count"] += 1
        user_depth[depth]["confidence"] = min(1.0, user_depth[depth]["usage_count"] / 10.0)
    
    def get_user_preferences(self, user: str) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        if user not in self.learning_patterns["user_preferences"]:
            return {}
        
        return self.learning_patterns["user_preferences"][user]
    
    def get_style_recommendation(self, user: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Å—Ç–∏–ª—é –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        if user not in self.learning_patterns["style_adaptations"]:
            return {"style": "default", "confidence": 0.0}
        
        user_styles = self.learning_patterns["style_adaptations"][user]
        
        # –í—ã–±–∏—Ä–∞–µ–º —Å—Ç–∏–ª—å —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –≤–µ—Å–æ–º
        best_style = max(user_styles.items(), key=lambda x: x[1]["weight"])
        
        return {
            "style": best_style[0],
            "weight": best_style[1]["weight"],
            "confidence": best_style[1]["confidence"],
            "all_styles": user_styles
        }
    
    def get_communication_level(self, user: str) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        if user not in self.learning_patterns["communication_patterns"]:
            return {"level": "standard", "confidence": 0.0}
        
        user_patterns = self.learning_patterns["communication_patterns"][user]
        
        # –í—ã–±–∏—Ä–∞–µ–º —É—Ä–æ–≤–µ–Ω—å —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –≤–µ—Å–æ–º
        best_level = max(user_patterns.items(), key=lambda x: x[1]["weight"])
        
        return {
            "level": best_level[0],
            "weight": best_level[1]["weight"],
            "confidence": best_level[1]["confidence"],
            "all_levels": user_patterns
        }
    
    def get_technical_depth(self, user: str) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –≥–ª—É–±–∏–Ω—ã –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        if user not in self.learning_patterns["technical_depth"]:
            return {"depth": "medium", "confidence": 0.0}
        
        user_depth = self.learning_patterns["technical_depth"][user]
        
        # –í—ã–±–∏—Ä–∞–µ–º –≥–ª—É–±–∏–Ω—É —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –≤–µ—Å–æ–º
        best_depth = max(user_depth.items(), key=lambda x: x[1]["weight"])
        
        return {
            "depth": best_depth[0],
            "weight": best_depth[1]["weight"],
            "confidence": best_depth[1]["confidence"],
            "all_depths": user_depth
        }
    
    def analyze_feedback_trends(self, user: str, days: int = 7) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏"""
        try:
            with open(self.interaction_log_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            cutoff_date = datetime.now() - timedelta(days=days)
            recent_interactions = []
            
            for line in lines:
                if line.strip():
                    record = json.loads(line)
                    if record.get("user") == user:
                        timestamp = datetime.fromisoformat(record["timestamp"])
                        if timestamp >= cutoff_date:
                            recent_interactions.append(record)
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç—Ä–µ–Ω–¥—ã
            positive_count = sum(1 for r in recent_interactions 
                               if r.get("feedback", {}).get("implicit") == "positive")
            negative_count = sum(1 for r in recent_interactions 
                               if r.get("feedback", {}).get("implicit") == "negative")
            
            total_interactions = len(recent_interactions)
            satisfaction_rate = positive_count / total_interactions if total_interactions > 0 else 0.0
            
            return {
                "total_interactions": total_interactions,
                "positive_feedback": positive_count,
                "negative_feedback": negative_count,
                "satisfaction_rate": satisfaction_rate,
                "trend": "improving" if satisfaction_rate > 0.7 else "declining" if satisfaction_rate < 0.3 else "stable"
            }
            
        except Exception as e:
            logger.error(f"‚ùå Feedback trend analysis failed: {e}")
            return {"error": str(e)}
    
    def schedule_learning_cycle(self):
        """–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ü–∏–∫–ª–∞ –æ–±—É—á–µ–Ω–∏—è"""
        # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ –∫–∞–∂–¥—ã–µ 6 —á–∞—Å–æ–≤
        scheduler.schedule_periodic_task(
            task_type="learning_analysis",
            interval_minutes=360,  # 6 —á–∞—Å–æ–≤
            name="Learning Pattern Analysis",
            description="Analyze interaction patterns and update learning models",
            priority=TaskPriority.BACKGROUND
        )
        
        logger.info("üìÖ Scheduled learning cycle analysis")

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–∏—Å—Ç–µ–º—ã –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏—è
reinforcement_tagger = ReinforcementTagger() 